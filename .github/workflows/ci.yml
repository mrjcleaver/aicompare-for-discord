name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run nightly tests at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18.x'
  POSTGRES_VERSION: '15'
  REDIS_VERSION: '7'

jobs:
  # Quality checks - linting, type checking, security
  quality-checks:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # For SonarCloud
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run ESLint
        run: npm run lint
        continue-on-error: true # Don't fail the build, but report issues
      
      - name: Run TypeScript type checking
        run: npm run typecheck
      
      - name: Run Prettier check
        run: npx prettier --check .
      
      - name: Security audit
        run: npm audit --audit-level high
        continue-on-error: true
      
      - name: Check for vulnerable dependencies
        run: npx audit-ci --config .audit-ci.json
        continue-on-error: true
      
      - name: SonarCloud Scan
        if: github.event_name != 'schedule'
        uses: SonarSource/sonarcloud-github-action@master
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  # Unit tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: ['18.x', '20.x']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run unit tests
        run: npm run test:unit
        env:
          NODE_ENV: test
      
      - name: Generate coverage report
        run: npm run test:coverage
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
          flags: unit-tests
          name: codecov-unit-${{ matrix.node-version }}

  # Integration tests with services
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_USER: postgres
          POSTGRES_DB: aicompare_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:${{ env.REDIS_VERSION }}
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Wait for PostgreSQL
        run: |
          until pg_isready -h localhost -p 5432 -U postgres; do
            echo "Waiting for PostgreSQL..."
            sleep 2
          done
      
      - name: Wait for Redis
        run: |
          until redis-cli -h localhost -p 6379 ping; do
            echo "Waiting for Redis..."
            sleep 2
          done
      
      - name: Setup test database
        run: |
          PGPASSWORD=postgres psql -h localhost -U postgres -d aicompare_test -c "SELECT 1;"
        env:
          PGPASSWORD: postgres
      
      - name: Run integration tests
        run: npm run test:integration
        env:
          NODE_ENV: test
          TEST_DB_HOST: localhost
          TEST_DB_PORT: 5432
          TEST_DB_NAME: aicompare_test
          TEST_DB_USER: postgres
          TEST_DB_PASSWORD: postgres
          TEST_REDIS_URL: redis://localhost:6379/15
      
      - name: Upload integration test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results
          path: |
            test-results/
            coverage/integration/

  # End-to-End tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_USER: postgres
          POSTGRES_DB: aicompare_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:${{ env.REDIS_VERSION }}
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Install Playwright browsers
        run: npx playwright install --with-deps
      
      - name: Build applications
        run: npm run build
        env:
          NODE_ENV: production
      
      - name: Run E2E tests
        run: npm run test:e2e
        env:
          NODE_ENV: test
          TEST_DB_HOST: localhost
          TEST_DB_PORT: 5432
          TEST_DB_NAME: aicompare_test
          TEST_DB_USER: postgres
          TEST_DB_PASSWORD: postgres
          TEST_REDIS_URL: redis://localhost:6379/15
          E2E_BASE_URL: http://localhost:3000
      
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results
          path: |
            test-results/
            playwright-report/
      
      - name: Upload E2E videos and screenshots
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: e2e-failures
          path: |
            test-results/**/*.png
            test-results/**/*.webm

  # Load testing (only on main branch and schedules)
  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.event_name == 'schedule'
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_USER: postgres
          POSTGRES_DB: aicompare_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:${{ env.REDIS_VERSION }}
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Build applications
        run: npm run build
      
      - name: Start applications
        run: |
          npm run start:api &
          npm run start:web &
          sleep 30 # Wait for services to start
        env:
          NODE_ENV: production
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/aicompare_test
          REDIS_URL: redis://localhost:6379
      
      - name: Run load tests
        run: npm run test:load
        env:
          LOAD_TEST_TARGET: http://localhost:3000
      
      - name: Upload load test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: load-test-results
          path: |
            tests/load/results/

  # Security testing
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run Snyk security scan
        run: npx snyk test --all-projects --severity-threshold=medium
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        continue-on-error: true
      
      - name: Run Bandit security scan (Python dependencies)
        if: hashFiles('**/requirements.txt') != ''
        run: |
          pip install bandit
          bandit -r . -f json -o bandit-report.json || true
      
      - name: OWASP ZAP security scan
        if: github.ref == 'refs/heads/main'
        run: |
          docker run -v $(pwd):/zap/wrk/:rw \
            -t owasp/zap2docker-stable zap-baseline.py \
            -t http://localhost:3000 \
            -J zap-report.json || true
      
      - name: Upload security scan results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-scan-results
          path: |
            bandit-report.json
            zap-report.json

  # Container security and build
  container-tests:
    name: Container Security & Build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker images
        run: |
          docker build -t aicompare/discord-bot ./packages/discord-bot
          docker build -t aicompare/api-server ./packages/api-server
          docker build -t aicompare/web-dashboard ./packages/web-dashboard
      
      - name: Scan Docker images for vulnerabilities
        run: |
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
            aquasec/trivy image aicompare/discord-bot
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
            aquasec/trivy image aicompare/api-server
          docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
            aquasec/trivy image aicompare/web-dashboard
        continue-on-error: true

  # Accessibility testing
  accessibility-tests:
    name: Accessibility Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Build web application
        run: npm run build:web
      
      - name: Start web application
        run: |
          npm run start:web &
          sleep 15
        env:
          NODE_ENV: production
      
      - name: Run accessibility tests with axe-core
        run: |
          npx @axe-core/cli http://localhost:3000 \
            --include-tags wcag2a,wcag2aa,wcag21aa \
            --exit
        continue-on-error: true
      
      - name: Run Lighthouse accessibility audit
        run: |
          npx lighthouse http://localhost:3000 \
            --only-categories=accessibility \
            --chrome-flags="--headless --no-sandbox" \
            --output=json \
            --output-path=lighthouse-accessibility.json
        continue-on-error: true
      
      - name: Upload accessibility test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: accessibility-results
          path: lighthouse-accessibility.json

  # Test results aggregation
  test-summary:
    name: Test Results Summary
    runs-on: ubuntu-latest
    needs: [quality-checks, unit-tests, integration-tests, e2e-tests]
    if: always()
    
    steps:
      - name: Download all test artifacts
        uses: actions/download-artifact@v3
      
      - name: Generate test summary
        run: |
          echo "# Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## Quality Checks" >> $GITHUB_STEP_SUMMARY
          echo "Status: ${{ needs.quality-checks.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## Unit Tests" >> $GITHUB_STEP_SUMMARY
          echo "Status: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## Integration Tests" >> $GITHUB_STEP_SUMMARY
          echo "Status: ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## E2E Tests" >> $GITHUB_STEP_SUMMARY
          echo "Status: ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "*/junit.xml" ]; then
            echo "## Detailed Results" >> $GITHUB_STEP_SUMMARY
            echo "Test reports are available in the artifacts." >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const results = {
              'quality-checks': '${{ needs.quality-checks.result }}',
              'unit-tests': '${{ needs.unit-tests.result }}',
              'integration-tests': '${{ needs.integration-tests.result }}',
              'e2e-tests': '${{ needs.e2e-tests.result }}'
            };
            
            let body = '## 🧪 Test Results\n\n';
            for (const [test, result] of Object.entries(results)) {
              const icon = result === 'success' ? '✅' : result === 'failure' ? '❌' : '⚠️';
              body += `${icon} **${test}**: ${result}\n`;
            }
            
            const allPassed = Object.values(results).every(r => r === 'success');
            body += allPassed ? '\n🎉 All tests passed!' : '\n⚠️ Some tests failed. Please check the logs.';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  # Deployment to staging (on main branch)
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [quality-checks, unit-tests, integration-tests, e2e-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: staging
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Build applications
        run: npm run build
        env:
          NODE_ENV: production
      
      - name: Deploy to staging
        run: |
          echo "🚀 Deploying to staging environment"
          # Add your deployment commands here
          # This could be AWS, Heroku, Railway, etc.
        env:
          STAGING_DEPLOY_TOKEN: ${{ secrets.STAGING_DEPLOY_TOKEN }}
      
      - name: Run smoke tests on staging
        run: |
          echo "🧪 Running smoke tests on staging"
          # Add smoke tests to verify deployment
        env:
          STAGING_URL: ${{ vars.STAGING_URL }}

  # Notification on failure
  notify-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: [quality-checks, unit-tests, integration-tests, e2e-tests]
    if: failure() && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
    
    steps:
      - name: Send Slack notification
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#ci-cd'
          text: |
            🚨 CI/CD Pipeline Failed!
            
            Repository: ${{ github.repository }}
            Branch: ${{ github.ref }}
            Commit: ${{ github.sha }}
            
            Please check the failed jobs and fix the issues.
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}